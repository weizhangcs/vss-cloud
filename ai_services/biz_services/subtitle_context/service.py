import json
import math
from collections import defaultdict
from datetime import timedelta
from pathlib import Path
from typing import Dict, Any, List
from pydantic import BaseModel

from django.conf import settings
from ai_services.ai_platform.llm.mixins import AIServiceMixin
from ai_services.ai_platform.llm.gemini_processor import GeminiProcessor
from ai_services.ai_platform.llm.cost_calculator import CostCalculator
from core.exceptions import BizException
from core.error_codes import ErrorCode
from .schemas import SubtitleContextPayload, SubtitleContextResult, OptimizedSubtitleItem


class SubtitleLine(BaseModel):
    index: int
    start_time: str
    end_time: str
    content: str


class SubtitleContextService(AIServiceMixin):
    """
    [Service] å­—å¹•ä¸Šä¸‹æ–‡æœåŠ¡ (v2 - åˆ†æ‰¹è§’è‰²æ¨ç†ç‰ˆ)
    ç­–ç•¥ï¼š
    1. è§£æ SRT ä¸ºç»“æ„åŒ–åˆ—è¡¨ã€‚
    2. å‹ç¼©å†…å®¹ (å»æ—¶é—´æˆ³)ã€‚
    3. åˆ†æ‰¹ (Batching) å–‚ç»™ AIï¼Œè§„é¿ Output Token é™åˆ¶ã€‚
    4. èšåˆç»“æœã€‚
    """

    # æ‰¹æ¬¡å¤§å°ï¼šå»ºè®® 100-200ã€‚
    # å¤ªå°æˆæœ¬é«˜ï¼ˆé‡å¤ Input contextï¼‰ï¼Œå¤ªå¤§å®¹æ˜“ç”± Output Limit å¯¼è‡´æˆªæ–­ã€‚
    BATCH_SIZE = 150

    def __init__(self, logger, gemini_processor: GeminiProcessor, cost_calculator: CostCalculator):
        self.logger = logger
        self.gemini_processor = gemini_processor
        self.cost_calculator = cost_calculator
        self.prompts_dir = Path(__file__).parent / "prompts"

    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        self.logger.info("ğŸš€ Starting Subtitle Role Inference (Batch Mode)...")

        task_input = SubtitleContextPayload(**payload)
        subtitle_full_path = self._resolve_path(task_input.subtitle_path)

        # 1. è§£æ SRT
        if not subtitle_full_path.exists():
            raise BizException(ErrorCode.FILE_IO_ERROR, f"File not found: {subtitle_full_path}")

        raw_srt_content = subtitle_full_path.read_text(encoding='utf-8-sig')  # Handle BOM
        all_lines = self._parse_srt(raw_srt_content)
        total_lines = len(all_lines)

        self.logger.info(f"Parsed {total_lines} lines. Strategy: Batch Processing (Size={self.BATCH_SIZE})")

        # 2. å‡†å¤‡å…¨å±€ä¸Šä¸‹æ–‡ (Known Characters)
        chars_str = ", ".join(task_input.known_characters) if task_input.known_characters else "None (Infer from text)"

        final_results = []
        total_usage = {}

        # 3. åˆ†æ‰¹å¾ªç¯
        # è®¡ç®—æ€»æ‰¹æ•°
        num_batches = math.ceil(total_lines / self.BATCH_SIZE)

        for batch_idx in range(num_batches):
            start_idx = batch_idx * self.BATCH_SIZE
            end_idx = min((batch_idx + 1) * self.BATCH_SIZE, total_lines)

            batch_lines = all_lines[start_idx:end_idx]

            self.logger.info(f"Processing Batch {batch_idx + 1}/{num_batches} (Lines {start_idx + 1}-{end_idx})...")

            # 3.1 å‹ç¼©å†…å®¹ï¼šåªç”Ÿæˆ "Index Content"
            compressed_text = "\n".join([f"{line.index} {line.content}" for line in batch_lines])

            # 3.2 æ„å»º Prompt
            prompt = self._build_prompt(
                "role_inference_batch",  # å¯¹åº”ä¸Šé¢çš„æ–° Prompt æ–‡ä»¶å
                lang=task_input.lang,
                character_list=chars_str,
                video_title=task_input.video_title or "Unknown",
                compressed_subtitles=compressed_text
            )

            # 3.3 è°ƒç”¨ AI
            try:
                response_data, usage = self.gemini_processor.generate_content(
                    model_name=task_input.model_name,
                    prompt=prompt,
                    temperature=0.1,  # æä½æ¸©åº¦ï¼Œç¡®ä¿æ ¼å¼ç¨³å®š
                    tools = None,  # <--- â›” å¿…é¡»æ˜¾å¼ç¦ç”¨å·¥å…·
                    tool_config = None  # <--- â›” å¿…é¡»æ˜¾å¼ç¦ç”¨å·¥å…·é…ç½®
                )

                # ç´¯åŠ  Cost
                self._calculate_and_merge_cost(task_input.model_name, usage, total_usage)

                # 3.4 è§£ææ˜ å°„
                mappings = response_data.get("mappings", [])

                # è½¬ä¸º Dict æ–¹ä¾¿æŸ¥æ‰¾: {index: speaker}
                speaker_map = {m.get("i"): m.get("s", "Unknown") for m in mappings}

                # 3.5 å›å¡«åˆ°ç»“æœ
                for line in batch_lines:
                    speaker = speaker_map.get(line.index, "Unknown")

                    # æ„é€ æœ€ç»ˆ Output Item
                    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸åšå¥å¼åˆå¹¶ï¼Œåªåšè§’è‰²è¯†åˆ«ï¼Œæ‰€ä»¥ content æ˜¯åŸå§‹çš„
                    final_results.append(OptimizedSubtitleItem(
                        index=line.index,
                        start_time=self._srt_time_to_seconds(line.start_time),
                        end_time=self._srt_time_to_seconds(line.end_time),
                        content=line.content,
                        speaker=speaker,
                        reasoning="Batch Inferred"
                    ))

            except Exception as e:
                self.logger.error(f"Batch {batch_idx + 1} failed: {e}")

                # [æ–°å¢] é»‘åŒ£å­ï¼šæ‰“å°å‡ºå¯¼è‡´å¤±è´¥çš„åŸå§‹å†…å®¹ï¼Œæ–¹ä¾¿æ’æŸ¥
                # åªæ‰“å°å‰500ä¸ªå­—ç¬¦ï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸
                self.logger.error(f"ğŸ’€ FAILED BATCH CONTENT (First 1000 chars):\n{compressed_text[:1000]}")

                # å…œåº•ï¼šå¦‚æœè¿™ä¸€æ‰¹å¤±è´¥äº†ï¼Œå¡« Unknownï¼Œä¸è¦è®©æ•´ä¸ªä»»åŠ¡æŒ‚æ‰
                for line in batch_lines:
                    final_results.append(OptimizedSubtitleItem(
                        index=line.index,
                        start_time=self._srt_time_to_seconds(line.start_time),
                        end_time=self._srt_time_to_seconds(line.end_time),
                        content=line.content,
                        speaker="Unknown (Error)",
                        reasoning="Inference Failed"
                    ))

        # =========================================================
        # Stage 3.5: Speaker Normalization (æ–°å¢)
        # =========================================================
        self.logger.info("Stage 3.5: Normalizing Speaker Names...")

        # 1. æå–æ‰€æœ‰å‡ºç°çš„åŸå§‹åå­—
        raw_speakers = list(set([item.speaker for item in final_results if item.speaker != "Unknown"]))

        if len(raw_speakers) > 0:
            # 2. è°ƒç”¨ AI ç”Ÿæˆæ˜ å°„è¡¨
            normalization_map = self._normalize_speakers_via_ai(
                raw_speakers,
                task_input.model_name,
                task_input.lang,
                total_usage
            )

            # 3. åº”ç”¨æ˜ å°„ (In-place Update)
            update_count = 0
            for item in final_results:
                if item.speaker in normalization_map:
                    original = item.speaker
                    new_name = normalization_map[original]
                    if original != new_name:
                        item.speaker = new_name
                        update_count += 1

            self.logger.info(f"Normalized {update_count} lines based on {len(normalization_map)} mappings.")

        # =========================================================
        # Stage 4: Post Processing (SRT è¿˜åŸ & è§’è‰²åˆ†æ)
        # =========================================================
        self.logger.info("Stage 4: Post-Processing (SRT Generation & Metrics)...")

        # 4.1 ç”Ÿæˆ ASS æ–‡ä»¶ (å¸¦ Speaker)
        output_ass_path = self._generate_ass_file(task_input.subtitle_path, final_results)

        # 4.2 è®¡ç®—è§’è‰²æŒ‡æ ‡ (é€‚é…ç‰ˆ)
        metrics_report = self._calculate_metrics(final_results)

        # 5. æ„é€ æœ€ç»ˆè¿”å›
        result = SubtitleContextResult(
            input_file=str(task_input.subtitle_path),
            optimized_subtitles=final_results,
            output_ass_path=str(output_ass_path),  # è¿”å›è·¯å¾„
            character_roster=metrics_report.get("character_roster", []),  # è¿”å›è§’è‰²äº‘
            stats={
                "total_lines": total_lines,
                "processed_lines": len(final_results),
                "batches": num_batches,
                "unique_characters": len(metrics_report.get("character_roster", []))
            },
            usage_report=total_usage
        )

        self.logger.info(f"âœ… Batch Processing Complete. Cost: ${total_usage.get('total_cost_usd', 0):.4f}")
        return result.model_dump()

    def _parse_srt(self, content: str) -> List[SubtitleLine]:
        """ç®€æ˜“ SRT è§£æå™¨"""
        # ç»Ÿä¸€æ¢è¡Œç¬¦
        content = content.replace('\r\n', '\n').replace('\r', '\n')

        # SRT å—ç”±ç©ºè¡Œåˆ†éš”
        blocks = content.strip().split('\n\n')

        parsed_lines = []
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    # Line 1: Index
                    idx = int(lines[0].strip())
                    # Line 2: Timecode
                    time_parts = lines[1].split(' --> ')
                    start, end = time_parts[0].strip(), time_parts[1].strip()
                    # Line 3+: Content
                    text = " ".join(lines[2:]).strip()  # åˆå¹¶å¤šè¡Œå­—å¹•æ–‡æœ¬

                    parsed_lines.append(SubtitleLine(
                        index=idx,
                        start_time=start,
                        end_time=end,
                        content=text
                    ))
                except Exception:
                    continue  # è·³è¿‡æŸåçš„å—

        return parsed_lines

    def _calculate_and_merge_cost(self, model_name: str, usage: Dict, total_usage: Dict):
        """ç´¯åŠ æˆæœ¬ (ä¿®å¤ç‰ˆï¼šå¢åŠ ç±»å‹å®‰å…¨æ£€æŸ¥)"""
        costs = self.cost_calculator.calculate(model_name, usage)

        # 1. ç´¯åŠ  Usage (Tokenæ•°)
        for k, v in usage.items():
            # æ’é™¤ bool (True/False) å’Œ str (å¦‚ timestamp)ï¼Œåªç´¯åŠ  int/float
            if isinstance(v, (int, float)) and not isinstance(v, bool):
                total_usage[k] = total_usage.get(k, 0) + v

        # 2. ç´¯åŠ  Costs (é‡‘é¢)
        for k, v in costs.items():
            # [å…³é”®ä¿®å¤] å¿…é¡»æ£€æŸ¥ç±»å‹ï¼Œè¿‡æ»¤æ‰ 'warning' ç­‰å­—ç¬¦ä¸²å­—æ®µ
            if isinstance(v, (int, float)):
                total_usage[k] = total_usage.get(k, 0) + v

    def _resolve_path(self, path_str: str) -> Path:
        p = Path(path_str)
        if p.is_absolute(): return p
        return settings.SHARED_ROOT / p

    def _srt_time_to_seconds(self, time_str: str) -> float:
        if not time_str: return 0.0
        try:
            time_str = time_str.replace(',', '.')
            hours, minutes, seconds = time_str.split(':')
            return float(hours) * 3600 + float(minutes) * 60 + float(seconds)
        except Exception:
            return 0.0

    # --- æ–°å¢è¾…åŠ©æ–¹æ³• ---

    def _generate_ass_file(self, original_path_str: str, items: List[OptimizedSubtitleItem]) -> Path:
        """ç”Ÿæˆ ASS å­—å¹•æ–‡ä»¶ (æ”¯æŒ Speaker å­—æ®µ)"""
        original_path = self._resolve_path(original_path_str)
        output_filename = f"{original_path.stem}_ai_labeled.ass"
        output_path = original_path.parent / output_filename

        def sec_to_ass_time(seconds: float) -> str:
            """12.345 -> 0:00:12.34 (H:MM:SS.cc)"""
            total_sec = int(seconds)
            cs = int((seconds - total_sec) * 100)  # Centiseconds
            m, s = divmod(total_sec, 60)
            h, m = divmod(m, 60)
            return f"{h}:{m:02d}:{s:02d}.{cs:02d}"

        # ASS Header Template (Standard 1080p)
        header = """[Script Info]
Title: VSS AI Generated Subtitle
ScriptType: v4.00+
PlayResX: 1920
PlayResY: 1080
WrapStyle: 0
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,50,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

        events = []
        for item in items:
            start_str = sec_to_ass_time(item.start_time)
            end_str = sec_to_ass_time(item.end_time)

            # æ¸…æ´—è§’è‰²åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢ç ´å ASS æ ¼å¼
            safe_speaker = item.speaker.replace(",", " ").strip() if item.speaker else "Unknown"
            # æ¸…æ´—æ–‡æœ¬ä¸­çš„æ¢è¡Œç¬¦
            safe_content = item.content.replace("\n", "\\N")

            # æ„é€  Event è¡Œ
            # Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
            line = f"Dialogue: 0,{start_str},{end_str},Default,{safe_speaker},0,0,0,,{safe_content}"
            events.append(line)

        full_content = header + "\n".join(events)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_content)

        try:
            return output_path.relative_to(settings.SHARED_ROOT)
        except ValueError:
            return str(output_path)

    def _calculate_metrics(self, items: List[OptimizedSubtitleItem]) -> Dict:
        """
        [ç®—æ³•é€‚é…] åŸºäºçº¯å­—å¹•æµçš„è§’è‰²é‡è¦åº¦è®¡ç®—ã€‚
        ç”±äºæ²¡æœ‰ Sceneï¼Œæˆ‘ä»¬å°† 'Presence' çš„å®šä¹‰é€€åŒ–ä¸º 'å‡ºç°åœ¨å¤šå°‘å¥å¯¹è¯ä¸­'ã€‚
        """
        metrics = defaultdict(
            lambda: {
                "dialogue_count": 0,
                "dialogue_total_length": 0,
                "dialogue_total_duration": 0.0,
                "raw_names": set(),
            }
        )

        exclude_patterns = ["Unknown", "Narrator", "News", "Radio"]

        # 1. ç»Ÿè®¡åŸºç¡€æ•°æ®
        for item in items:
            raw_speaker = item.speaker.strip()
            if not raw_speaker: continue
            if any(raw_speaker.startswith(p) for p in exclude_patterns): continue

            # å½’ä¸€åŒ– Key
            speaker_key = " ".join(raw_speaker.lower().split())

            metrics[speaker_key]["raw_names"].add(raw_speaker)
            metrics[speaker_key]["dialogue_count"] += 1
            metrics[speaker_key]["dialogue_total_length"] += len(item.content)

            dur = item.end_time - item.start_time
            metrics[speaker_key]["dialogue_total_duration"] += dur

        # 2. è®¡ç®—å¾—åˆ†
        roster = []
        if not metrics:
            return {"character_roster": []}

        target_chars = metrics.keys()

        def safe_max(iterable):
            val = max(iterable, default=0)
            return val if val > 0 else 1

        # è¿™é‡Œçš„ Max åŸºå‡†åªæœ‰ä¸‰ä¸ªç»´åº¦ (å»æ‰äº† Scene å’Œ Interaction)
        max_vals = {
            "dialogue": safe_max(metrics[c]["dialogue_count"] for c in target_chars),
            "length": safe_max(metrics[c]["dialogue_total_length"] for c in target_chars),
            "duration": safe_max(metrics[c]["dialogue_total_duration"] for c in target_chars),
        }

        for key, data in metrics.items():
            # ç®€åŒ–ç‰ˆå…¬å¼ï¼šåªçœ‹è¯é‡å’Œæ—¶é•¿
            # presence_score å®é™…ä¸Šå°±æ˜¯æ´»è·ƒåº¦
            score = (
                    (data["dialogue_count"] / max_vals["dialogue"]) * 0.4 +
                    (data["dialogue_total_length"] / max_vals["length"]) * 0.3 +
                    (data["dialogue_total_duration"] / max_vals["duration"]) * 0.3
            )

            display_name = list(data["raw_names"])[0] if data["raw_names"] else key

            roster.append({
                "name": display_name,
                "key": key,
                "weight_score": round(score, 4),  # ç»å¯¹åˆ†å€¼ (0-1)
                "_raw_score": score,
                "stats": {
                    "lines": data["dialogue_count"],
                    "duration_sec": round(data["dialogue_total_duration"], 2)
                },
                "variations": list(data["raw_names"])
            })

        # 3. æ’åºä¸ç™¾åˆ†æ¯”
        roster.sort(key=lambda x: x["weight_score"], reverse=True)

        top_score = roster[0]["_raw_score"] if roster else 1
        for r in roster:
            pct = (r["_raw_score"] / top_score) * 100 if top_score > 0 else 0
            r["weight_percent"] = f"{round(pct, 1)}%"
            del r["_raw_score"]

        return {"character_roster": roster}

    def _normalize_speakers_via_ai(self, raw_names: List[str], model_name: str, lang: str, total_usage: Dict) -> Dict[
        str, str]:
        """è°ƒç”¨ AI è¿›è¡Œåå­—å½’ä¸€åŒ–"""
        # å¦‚æœåå­—å¤ªå°‘ï¼Œä¸ç”¨ AI
        if len(raw_names) < 3:
            return {n: n for n in raw_names}

        # æ„é€  Prompt
        names_str = json.dumps(raw_names, indent=2)
        prompt = self._build_prompt(
            "speaker_normalization",  # å¯¹åº”æ–°å»ºçš„ txt
            lang=lang,
            name_list=names_str
        )

        try:
            # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ä»»åŠ¡ï¼ŒFlash æ¨¡å‹è¶³å¤Ÿäº†
            response_data, usage = self.gemini_processor.generate_content(
                model_name=model_name,
                prompt=prompt,
                temperature=0.1,
                tools = None,  # <--- â›” å¿…é¡»æ˜¾å¼ç¦ç”¨å·¥å…·
                tool_config = None  # <--- â›” å¿…é¡»æ˜¾å¼ç¦ç”¨å·¥å…·é…ç½®
            )
            self._calculate_and_merge_cost(model_name, usage, total_usage)

            return response_data.get("normalization_map", {})

        except Exception as e:
            self.logger.error(f"Speaker Normalization failed: {e}")
            # å…œåº•ï¼šä¸æ”¹åŠ¨
            return {}