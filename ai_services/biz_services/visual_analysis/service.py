import json
import shutil
import subprocess
from collections import defaultdict
from datetime import timedelta
from pathlib import Path
from typing import Dict, Any, List

from PIL import Image
from django.conf import settings

from ai_services.ai_platform.llm.gemini_processor import GeminiProcessor
from ai_services.ai_platform.llm.cost_calculator import CostCalculator
from ai_services.ai_platform.llm.mixins import AIServiceMixin
from core.exceptions import BizException
from core.error_codes import ErrorCode

from .schemas import (
    VisualAnalysisPayload, VisualAnalysisResult, RawSlice, VisualTag, RefinedSlice
)


class VisualAnalysisService(AIServiceMixin):
    """
    [Service] è§†è§‰åˆ†ææœåŠ¡ (Visual Analysis Service)
    èŒè´£ï¼š
    1. è§†è§‰æ¨ç† (Visual Inference): å¯¹ raw_slices ä¸­çš„ visual_segment è¿›è¡Œæˆªå›¾ + Gemini VLM åˆ†æã€‚
    2. è¯­ä¹‰æ•´å½¢ (Semantic Refinement): å¯¹å…¨é‡åˆ‡ç‰‡è¿›è¡Œæ–‡æœ¬è¯­ä¹‰åˆå¹¶ä¸æ‰“æ ‡ã€‚
    3. èšåˆè¾“å‡º: ç”Ÿæˆä¾› Workbench ä½¿ç”¨çš„æœ€ç»ˆ Timelineã€‚
    """

    def __init__(self,
                 logger,
                 gemini_processor: GeminiProcessor,
                 cost_calculator: CostCalculator):
        self.logger = logger
        self.gemini_processor = gemini_processor
        self.cost_calculator = cost_calculator

        # è·¯å¾„é…ç½®
        self.prompts_dir = Path(__file__).parent / "prompts"
        self.work_dir = settings.SHARED_TMP_ROOT / "visual_analysis_workspace"
        self.work_dir.mkdir(parents=True, exist_ok=True)

        # ä¸´æ—¶å¸§ä¿å­˜ç›®å½•
        self.frames_dir = self.work_dir / "frames"
        self.frames_dir.mkdir(exist_ok=True)

    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        self.logger.info("ğŸš€ Starting Visual Analysis Service...")

        # 1. è§£æ Payload
        try:
            task_input = VisualAnalysisPayload(**payload)
        except Exception as e:
            raise BizException(ErrorCode.PAYLOAD_VALIDATION_ERROR, f"Schema Error: {e}")

        # 2. å‡†å¤‡æ–‡ä»¶è·¯å¾„ (å…¼å®¹ç»å¯¹/ç›¸å¯¹è·¯å¾„)
        video_full_path = self._resolve_path(task_input.video_path)
        raw_json_full_path = self._resolve_path(task_input.raw_slices_path)

        # 3. åŠ è½½ Raw Slices
        with open(raw_json_full_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            raw_slices = [RawSlice(**s) for s in raw_data.get("slices", [])]
            total_duration = raw_data.get("total_duration", 0.0)

        total_usage = {}  # ç”¨äºç´¯è®¡ Token æ¶ˆè€—

        # =========================================================
        # Stage 1: Visual Inference (é’ˆå¯¹ Visual Segments)
        # =========================================================
        self.logger.info("Stage 1: Processing Visual Segments...")

        visual_prompt_tpl = self._load_prompt_template(task_input.lang, "visual_tagging")

        processed_slices = []
        for idx, slice_item in enumerate(raw_slices):
            # å¿…é¡»ä½¿ç”¨ model_copyï¼Œå¦åˆ™ä¿®æ”¹ä¼šå½±å“åŸå§‹å¯¹è±¡å¼•ç”¨
            current_slice = slice_item.model_copy()

            if current_slice.processing_strategy == "visual_inference":
                mid_point = (current_slice.start_time + current_slice.end_time) / 2
                frame_path = self._extract_frame(video_full_path, mid_point, idx)

                if frame_path:
                    # è®°å½•ç¼©ç•¥å›¾è·¯å¾„ (ç›¸å¯¹è·¯å¾„ï¼Œä¾›å‰ç«¯è®¿é—®)
                    try:
                        rel_thumb = frame_path.relative_to(settings.SHARED_ROOT)
                    except ValueError:
                        rel_thumb = frame_path.name
                    current_slice.thumbnail_path = str(rel_thumb)

                    # è°ƒç”¨ Gemini VLM
                    try:
                        pil_image = Image.open(frame_path)
                        response_data, usage = self.gemini_processor.generate_content(
                            model_name=task_input.visual_model,
                            prompt=[visual_prompt_tpl, pil_image],  # å¤šæ¨¡æ€ List è¾“å…¥
                            temperature=0.2
                        )

                        # è§£æç»“æœ
                        visual_tag = VisualTag(**response_data)
                        current_slice.visual_analysis = visual_tag

                        # è®¡è´¹èšåˆ
                        self._calculate_and_merge_cost(task_input.visual_model, usage, total_usage)

                    except Exception as e:
                        self.logger.error(f"Visual Inference failed for slice {idx}: {e}")

            processed_slices.append(current_slice)

        # =========================================================
        # Stage 2: Semantic Refinement (å…¨é‡åˆ‡ç‰‡)
        # =========================================================
        self.logger.info("Stage 2: Semantic Refinement...")

        # å‡†å¤‡ Prompt ä¸Šä¸‹æ–‡
        # ç®€åŒ–æ•°æ®ç»“æ„ä»¥èŠ‚çœ Token
        context_slices = []
        for i, s in enumerate(processed_slices):
            item = {
                "id": i,
                "time": f"{s.start_time}-{s.end_time}",
                "type": s.type,
                "content": s.text_content if s.type == "dialogue" else f"[Visual: {s.visual_analysis.action if s.visual_analysis else 'Unknown'}]"
            }
            context_slices.append(item)

        semantic_prompt = self._build_prompt(
            "semantic_refinement",
            lang=task_input.lang,
            slices_json=json.dumps(context_slices, indent=2)
        )

        # è°ƒç”¨ Gemini Logic
        try:
            refine_resp, refine_usage = self.gemini_processor.generate_content(
                model_name=task_input.semantic_model,
                prompt=semantic_prompt,
                temperature=0.1
            )
            self._calculate_and_merge_cost(task_input.semantic_model, refine_usage, total_usage)

            refined_timeline_raw = refine_resp.get("refined_timeline", [])

        except Exception as e:
            self.logger.error(f"Semantic Refinement failed: {e}")
            raise BizException(ErrorCode.LLM_INFERENCE_ERROR, f"Refinement failed: {e}")

        # =========================================================
        # Stage 3: Aggregation (å›å¡«æ•°æ®)
        # =========================================================
        final_timeline = []

        # å»ºç«‹åŸå§‹åˆ‡ç‰‡æŸ¥æ‰¾è¡¨
        raw_map = {i: s for i, s in enumerate(processed_slices)}

        for item in refined_timeline_raw:
            # åŸºç¡€å­—æ®µ
            refined_slice = RefinedSlice(
                start_time=item["start_time"],
                end_time=item["end_time"],
                type=item["type"],
                topic=item.get("topic", "Unknown"),
                content=item["content"],
                source_slice_ids=item.get("source_slice_ids", []),
                refinement_note=f"Merged {len(item.get('source_slice_ids', []))} slices"
            )

            # å¦‚æœæ˜¯ Visual Segmentï¼Œéœ€è¦å›å¡«åˆšæ‰ Stage 1 è·‘å‡ºæ¥çš„è§†è§‰ç»“æœ
            if refined_slice.type == "visual_segment":
                # ç­–ç•¥ï¼šæ‰¾åˆ°é‡å æœ€å¤§çš„é‚£ä¸ªåŸå§‹ Visual Slice
                best_match = None
                for raw_idx in refined_slice.source_slice_ids:
                    raw_s = raw_map.get(raw_idx)
                    if raw_s and raw_s.type == "visual_segment":
                        best_match = raw_s
                        break  # é€šå¸¸ Visual Segment æ˜¯ä¸€å¯¹ä¸€çš„

                # å¦‚æœ source_ids ä¸ºç©ºæˆ–æ²¡æ‰¾åˆ° (LLM å¯èƒ½è°ƒæ•´äº† ID)ï¼Œå°è¯•æ—¶é—´åŒ¹é…å…œåº•
                if not best_match:
                    for raw_s in processed_slices:
                        if raw_s.type == "visual_segment" and abs(raw_s.start_time - refined_slice.start_time) < 0.1:
                            best_match = raw_s
                            break

                if best_match:
                    refined_slice.visual_tags = best_match.visual_analysis
                    refined_slice.thumbnail_path = best_match.thumbnail_path

            final_timeline.append(refined_slice)

        # 3. æ„å»ºæœ€ç»ˆç»“æœ
        result = VisualAnalysisResult(
            video_path=task_input.video_path,
            total_duration=total_duration,
            timeline=final_timeline,
            stats={
                "original_slices": len(raw_slices),
                "refined_slices": len(final_timeline)
            },
            usage_report=total_usage
        )

        self.logger.info(f"âœ… Service Finished. Total Cost: ${total_usage.get('total_cost_usd', 0):.4f}")
        return result.model_dump()

    def _resolve_path(self, path_str: str) -> Path:
        """è§£æè·¯å¾„ï¼šå¦‚æœæ˜¯ç»å¯¹è·¯å¾„åˆ™ä¿æŒï¼Œå¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„åˆ™åŸºäº SHARED_ROOT"""
        p = Path(path_str)
        if p.is_absolute():
            return p
        return settings.SHARED_ROOT / p

    def _extract_frame(self, video_path: Path, timestamp: float, idx: int) -> Path:
        """FFmpeg æˆªå›¾"""
        out_name = f"frame_{video_path.stem}_{timestamp:.2f}_{idx}.jpg"
        out_path = self.frames_dir / out_name

        if out_path.exists():
            return out_path

        ffmpeg_bin = shutil.which("ffmpeg") or "ffmpeg"
        cmd = [
            ffmpeg_bin, "-y", "-ss", str(timestamp),
            "-i", str(video_path),
            "-frames:v", "1", "-q:v", "2",
            str(out_path)
        ]

        try:
            subprocess.run(
                cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, stdin=subprocess.DEVNULL, check=True
            )
            return out_path
        except Exception as e:
            self.logger.warning(f"FFmpeg extraction failed for {video_path}: {e}")
            return None

    def _calculate_and_merge_cost(self, model_name: str, usage: Dict, total_usage: Dict):
        """è®¡ç®—æˆæœ¬å¹¶ç´¯åŠ åˆ°æ€»æŠ¥è¡¨"""
        costs = self.cost_calculator.calculate(model_name, usage)

        # ç´¯åŠ  Token
        total_usage["total_prompt_tokens"] = total_usage.get("total_prompt_tokens", 0) + usage.get("prompt_tokens", 0)
        total_usage["total_completion_tokens"] = total_usage.get("total_completion_tokens", 0) + usage.get(
            "completion_tokens", 0)

        # ç´¯åŠ  Cost
        current_usd = costs.get("cost_usd", 0)
        total_usage["total_cost_usd"] = total_usage.get("total_cost_usd", 0) + current_usd
        total_usage["total_cost_rmb"] = total_usage.get("total_cost_rmb", 0) + costs.get("cost_rmb", 0)