# æ–‡ä»¶è·¯å¾„: ai_services/rag/deployer.py
# æè¿°: [é‡æ„å] RAGéƒ¨ç½²å™¨æœåŠ¡ï¼Œå·²å®Œå…¨è§£è€¦ï¼Œé€šè¿‡ä¾èµ–æ³¨å…¥æ¨¡å¼è¿è¡Œã€‚
# ç‰ˆæœ¬: 2.0 (Decoupled & Reviewed)

import json
import logging
from collections import defaultdict
from pathlib import Path

import vertexai
from google.cloud import storage
from google.api_core import exceptions as google_exceptions
from core.exceptions import RateLimitException # [æ–°å¢]

from .corpus_manager import CorpusManager
from .data_manager import DataManager
from .schemas import NarrativeBlueprint, IdentifiedFact

from file_service.infrastructure.gcs_storage import upload_directory_to_gcs

class RagDeployer:
    """
    RAGéƒ¨ç½²å™¨æœåŠ¡ (RAG Deployer Service)ã€‚

    æœ¬æœåŠ¡è´Ÿè´£å°†èåˆäº†å¢å¼ºäº‹å®çš„å‰§æœ¬æ•°æ®ï¼Œå¤„ç†æˆRAGå¼•æ“æ‰€éœ€çš„å¯Œæ–‡æœ¬æ–‡æ¡£ï¼Œ
    ä¸Šä¼ è‡³Google Cloud Storage (GCS)ï¼Œå¹¶è§¦å‘Vertex AI RAGå¼•æ“çš„æ–‡ä»¶åŒæ­¥ã€‚

    è®¾è®¡åŸåˆ™:
    - **è§£è€¦**: ä¸ç›´æ¥ä¾èµ–ä»»ä½•æ¡†æ¶ï¼ˆå¦‚Djangoï¼‰ã€‚æ‰€æœ‰é…ç½®ï¼ˆé¡¹ç›®IDã€å¯†é’¥ã€è·¯å¾„ï¼‰å‡é€šè¿‡ä¾èµ–æ³¨å…¥ä¼ å…¥ã€‚
    - **èŒè´£å•ä¸€**: ä¸“æ³¨äºâ€œéƒ¨ç½²RAGè¯­æ–™åº“â€è¿™ä¸€æ ¸å¿ƒä»»åŠ¡ã€‚
    - **å¹‚ç­‰æ€§**: èƒ½å¤Ÿå¤„ç†è¯­æ–™åº“å·²å­˜åœ¨ï¼ˆæ›´æ–°ï¼‰å’Œä¸å­˜åœ¨ï¼ˆåˆ›å»ºï¼‰ä¸¤ç§æƒ…å†µã€‚
    """

    def __init__(self, project_id: str, location: str, logger: logging.Logger):
        """
        åˆå§‹åŒ–RAGéƒ¨ç½²å™¨ã€‚

        Args:
            project_id (str): Google Cloud é¡¹ç›®IDã€‚
            location (str): Google Cloud åŒºåŸŸ (e.g., "us-central1")ã€‚
            logger (logging.Logger): ä¸€ä¸ªç”±å¤–éƒ¨è°ƒç”¨æ–¹ä¼ å…¥çš„ã€å·²é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨å®ä¾‹ã€‚
        """
        self.project_id = project_id
        self.location = location
        self.logger = logger

        # åˆå§‹åŒ– Managers
        try:
            vertexai.init(project=self.project_id, location=self.location)
            self.corpus_manager = CorpusManager()
            self.data_manager = DataManager()
            self.logger.info(f"RagDeployer initialized (Project: {project_id}, Location: {location})")
        except Exception as e:
            self.logger.error(f"Vertex AI initialization failed: {e}", exc_info=True)
            raise

    def execute(self,
                corpus_display_name: str,
                blueprint_path: Path,
                facts_path: Path,
                gcs_bucket_name: str,
                staging_dir: Path,
                org_id: str,
                asset_id: str):
        """
        æ‰§è¡Œå®Œæ•´çš„éƒ¨ç½²æµç¨‹ã€‚

        æ­¤æ–¹æ³•ç¼–æ’äº†ä»æ•°æ®èåˆåˆ°æœ€ç»ˆè§¦å‘RAGå¼•æ“åŒæ­¥çš„å…¨éƒ¨æ­¥éª¤ã€‚

        Args:
            corpus_display_name (str): RAGè¯­æ–™åº“çš„ç›®æ ‡æ˜¾ç¤ºåç§°ã€‚è¿™æ˜¯å®ç°ç§Ÿæˆ·éš”ç¦»çš„å…³é”®ï¼Œ
                                       é€šå¸¸ç”± "series_id" å’Œ "instance_id" æ‹¼æ¥è€Œæˆã€‚
            blueprint_path (Path): æœ¬åœ°ä¸´æ—¶ç›®å½•ä¸­ narrative_blueprint.json æ–‡ä»¶çš„è·¯å¾„ã€‚
            facts_path (Path): æœ¬åœ°ä¸´æ—¶ç›®å½•ä¸­ character_facts.json æ–‡ä»¶çš„è·¯å¾„ã€‚
            gcs_bucket_name (str): ç”¨äºæš‚å­˜RAGæºæ–‡ä»¶çš„GCSæ¡¶åç§°ã€‚
            staging_dir (Path): ç”¨äºåœ¨æœ¬åœ°ç”Ÿæˆå¯Œæ–‡æœ¬æ–‡æ¡£çš„ä¸´æ—¶ç›®å½•ã€‚

        Returns:
            Dict: ä¸€ä¸ªåŒ…å«éƒ¨ç½²ç»“æœä¿¡æ¯çš„å­—å…¸ï¼Œç”¨äºCelery Taskè®°å½•ã€‚
        """
        self.logger.info("=" * 20 + f" ğŸš€ RAG éƒ¨ç½²ä»»åŠ¡å¯åŠ¨ (Corpus: {corpus_display_name}) ğŸš€ " + "=" * 20)

        try:
            # æ­¥éª¤ 1 & 2: æœ¬åœ°æ•°æ®èåˆä¸ç”Ÿæˆ (ä¿æŒåŸæœ‰é€»è¾‘)
            gcs_uri, total_scenes = self._fuse_and_prepare_files(
                source_blueprint_path=blueprint_path,
                enhanced_facts_path=facts_path,
                staging_dir=staging_dir,
                gcs_bucket_name=gcs_bucket_name,
                org_id=org_id,
                asset_id=asset_id
            )

            # æ­¥éª¤ 3: ä¸Šä¼ åˆ° GCS (ä¿æŒåŸæœ‰é€»è¾‘)
            self._upload_dir_to_gcs(
                local_dir=staging_dir,
                gcs_uri=gcs_uri,
            )

            # æ­¥éª¤ 4: éƒ¨ç½²åˆ° RAG Engine (ä½¿ç”¨ Manager)
            self._deploy_to_rag_engine(
                corpus_display_name=corpus_display_name,
                gcs_uri=gcs_uri
            )

            self.logger.info(f"âœ… RAG éƒ¨ç½²æˆåŠŸå®Œæˆã€‚Total Scenes: {total_scenes}")
            return {
                "message": "RAG deployment process initiated successfully.",
                "corpus_name": corpus_display_name,
                "source_gcs_uri": gcs_uri,
                "total_scene_count": total_scenes
            }

        except Exception as e:
            if isinstance(e, (google_exceptions.TooManyRequests, google_exceptions.ResourceExhausted)):
                raise RateLimitException(msg=str(e), provider="GoogleVertexAI") from e
            self.logger.critical(f"éƒ¨ç½²æµç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            raise

    def _fuse_and_prepare_files(self, source_blueprint_path: Path, enhanced_facts_path: Path, staging_dir: Path,
                                gcs_bucket_name: str, org_id: str, asset_id: str) -> tuple[str, int]:
        """åœ¨æœ¬åœ°å¤„ç†æ–‡ä»¶ï¼šåŠ è½½ã€èåˆã€ç”Ÿæˆå¯Œæ–‡æœ¬ã€‚"""
        self.logger.info(f"â–¶ï¸ æ­¥éª¤ 1/4: æ­£åœ¨åŠ è½½ç§Ÿæˆ· '{org_id}' çš„æºæ•°æ®......")
        try:
            # ä½¿ç”¨Pydanticæ¨¡å‹åŠ è½½å’ŒéªŒè¯è¾“å…¥æ–‡ä»¶ï¼Œç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®ã€‚
            json_content = source_blueprint_path.read_text(encoding='utf-8')
            blueprint = NarrativeBlueprint.model_validate_json(json_content)

            with enhanced_facts_path.open('r', encoding='utf-8') as f:
                facts_data = json.load(f)

            # å°†æ‰å¹³çš„factsåˆ—è¡¨è½¬æ¢ä¸ºPydanticå¯¹è±¡ï¼Œå¹¶æ³¨å…¥äº‹å®çš„å½’å±è€…ï¼ˆcharacter_nameï¼‰ã€‚
            all_facts = []
            facts_by_character_map = facts_data.get("identified_facts_by_character", {})
            for char_name, facts_list in facts_by_character_map.items():
                for fact_dict in facts_list:
                    # [æ ¸å¿ƒä¿®å¤] é˜²å¾¡æ€§ç¼–ç¨‹ï¼šå¼ºåˆ¶å°† value è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    # è§£å†³ LLM è¾“å‡ºæ•´æ•°ç±»å‹ (å¦‚å¹´é¾„: 23) å¯¼è‡´ Pydantic æ ¡éªŒå¤±è´¥çš„é—®é¢˜
                    if "value" in fact_dict:
                        fact_dict["value"] = str(fact_dict["value"])

                    # æ„é€ æ–°çš„å­—å…¸å¹¶æ³¨å…¥ owner
                    fact_dict_with_owner = {**fact_dict, "character_name": char_name}
                    all_facts.append(IdentifiedFact(**fact_dict_with_owner))
            self.logger.info("âœ… æºæ•°æ®ä¸å¢å¼ºäº‹å®åŠ è½½å¹¶æ ¡éªŒæˆåŠŸã€‚")
            total_scenes = len(blueprint.scenes)

        except Exception as e:
            self.logger.error(f"âŒ ä¸¥é‡é”™è¯¯: åŠ è½½æˆ–è§£ææ–‡ä»¶æ—¶å¤±è´¥ã€‚\n   å…·ä½“é”™è¯¯: {e}", exc_info=True)
            raise

        self.logger.info("â–¶ï¸ æ­¥éª¤ 2/4: æ­£åœ¨å°†å¢å¼ºäº‹å®èåˆåˆ°å‰§æœ¬åœºæ™¯ä¸­...")
        facts_by_scene = defaultdict(list)
        for fact in all_facts:
            facts_by_scene[str(fact.scene_id)].append(fact)

        for scene_id, scene_obj in blueprint.scenes.items():
            if scene_id in facts_by_scene:
                scene_obj.enhanced_facts = facts_by_scene[scene_id]
        self.logger.info("âœ… æ•°æ®èåˆå®Œæˆã€‚")

        # ç¡®ä¿æœ¬åœ°æš‚å­˜ç›®å½•å­˜åœ¨ã€‚
        staging_dir.mkdir(parents=True, exist_ok=True)
        project_name = blueprint.project_metadata.project_name
        self.logger.info(f"â–¶ï¸ æ­¥éª¤ 3/4: æ­£åœ¨ä¸º '{project_name}' (Asset: {asset_id}) ç”Ÿæˆå¯Œæ–‡æœ¬æ–‡ä»¶...")

        # éå†æ¯ä¸ªåœºæ™¯ï¼Œè°ƒç”¨Pydanticæ¨¡å‹çš„æ–¹æ³•ç”ŸæˆRAGæ‰€éœ€çš„å¯Œæ–‡æœ¬å†…å®¹ã€‚
        for scene_id, scene_obj in blueprint.scenes.items():
            # [æ ¸å¿ƒä¿®æ”¹] ä¼ å…¥ asset_id (UUID) ä½œä¸º RAG æ–‡æ¡£çš„å…ƒæ•°æ®
            rich_text_content = scene_obj.to_rag_text(asset_id=asset_id, lang='zh')

            # [æ ¸å¿ƒä¿®æ”¹] æ–‡ä»¶åä½¿ç”¨ asset_id ç¡®ä¿å”¯ä¸€æ€§å’Œç¨³å®šæ€§
            # æ ¼å¼: {asset_id}_scene_{scene_id}_enhanced.txt
            scene_file_path = staging_dir / f"{asset_id}_scene_{scene_id}_enhanced.txt"
            scene_file_path.write_text(rich_text_content, encoding='utf-8')
        self.logger.info(f"âœ… å¯Œæ–‡æœ¬æ–‡æ¡£å·²åœ¨æœ¬åœ°æš‚å­˜ç›®å½• '{staging_dir}' ç”Ÿæˆã€‚")

        # æ„å»ºå¹¶è¿”å›GCSçš„ç›®æ ‡URIï¼Œç”¨äºåç»­çš„ä¸Šä¼ å’ŒRAGåŒæ­¥ã€‚
        gcs_uri = f"gs://{gcs_bucket_name}/rag-engine-source/{org_id}/{asset_id}"
        return gcs_uri, total_scenes

    def _upload_dir_to_gcs(self, local_dir: Path, gcs_uri: str):
        """å°†æœ¬åœ°ç›®å½•ä¸­çš„æ‰€æœ‰.txtæ–‡ä»¶ä¸Šä¼ åˆ°æŒ‡å®šçš„GCSè·¯å¾„ã€‚"""
        if not gcs_uri.startswith("gs://"):
            raise ValueError(f"Invalid GCS URI: {gcs_uri}")

        parts = gcs_uri.replace("gs://", "").split("/", 1)
        bucket_name = parts[0]
        # å¦‚æœæ²¡æœ‰åç»­è·¯å¾„ï¼Œprefix ä¸ºç©ºå­—ç¬¦ä¸²
        gcs_prefix = parts[1] if len(parts) > 1 else ""

        self.logger.info(f"â–¶ï¸ æ­¥éª¤ 4/4: æ­£åœ¨è°ƒç”¨ file_service ä¸Šä¼ ç›®å½•åˆ°: '{gcs_uri}'...")

        try:
            # ç›´æ¥è°ƒç”¨åŸºç¡€è®¾æ–½å±‚çš„é€šç”¨æ–¹æ³•
            upload_directory_to_gcs(
                local_dir=local_dir,
                bucket_name=bucket_name,
                gcs_prefix=gcs_prefix
            )
            self.logger.info(f"âœ… æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ æˆåŠŸ (via file_service)ï¼")
        except Exception as e:
            self.logger.error(f"âŒ é”™è¯¯: ä¸Šä¼ åˆ°GCSå¤±è´¥: {e}", exc_info=True)
            raise

    def _deploy_to_rag_engine(self, corpus_display_name: str, gcs_uri: str):
        """ä½¿ç”¨ CorpusManager å’Œ DataManager å®Œæˆéƒ¨ç½²ã€‚"""
        self.logger.info(f"â–¶ï¸ [æœ€ç»ˆæ­¥éª¤]: åŒæ­¥æ•°æ®è‡³ RAG Engine...")

        # 1. è·å–æˆ–åˆ›å»º Corpus
        corpus = self.corpus_manager.get_corpus_by_display_name(corpus_display_name)
        if not corpus:
            self.logger.info(f"   Corpus '{corpus_display_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            corpus = self.corpus_manager.create_corpus(display_name=corpus_display_name)
        else:
            self.logger.info(f"   Corpus '{corpus_display_name}' å·²å­˜åœ¨ (ID: {corpus.name})ï¼Œå‡†å¤‡æ›´æ–°ã€‚")

        # 2. å¯¼å…¥æ–‡ä»¶
        self.logger.info(f"   å‘èµ·æ–‡ä»¶å¯¼å…¥: {gcs_uri}")
        self.data_manager.import_files(
            corpus_name=corpus.name,
            gcs_uris=[gcs_uri]
        )