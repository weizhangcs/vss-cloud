import sys
import json
import shutil
import uuid
from pathlib import Path
from typing import Dict, Any

# ==============================================================================
# 0. ç¯å¢ƒè·¯å¾„è®¾ç½® (Path Setup)
# ==============================================================================
# å‡è®¾è„šæœ¬ä½äº tests/ai_services/analysis/ ç›®å½•ä¸‹
current_file = Path(__file__).resolve()
project_root = current_file.parents[3]  # å›é€€åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.append(str(project_root))

print(f"Project Root added to path: {project_root}")

try:
    # 1. å¯¼å…¥ä¸šåŠ¡ç»„ä»¶
    from ai_services.biz_services.analysis.character.character_identifier import CharacterIdentifier
    from ai_services.biz_services.narrative_dataset import NarrativeDataset

    # 2. å¯¼å…¥çœŸå®åŸºç¡€è®¾æ–½
    from ai_services.ai_platform.llm.gemini_processor import GeminiProcessor
    from ai_services.ai_platform.llm.cost_calculator import CostCalculator

    # 3. å¯¼å…¥æ‚¨æä¾›çš„ Bootstrap å·¥å…·
    from tests.lib.bootstrap import bootstrap_local_env_and_logger

    print("âœ… Successfully imported all modules.")
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    print("è¯·ç¡®ä¿ utils/local_execution_bootstrap.py å­˜åœ¨ä¸” PYTHONPATH æ­£ç¡®ã€‚")
    sys.exit(1)


# ==============================================================================
# 1. å‡†å¤‡ä¸´æ—¶èµ„æºæ–‡ä»¶ (Schema & Localization)
# ==============================================================================
def setup_temp_resources(work_dir: Path):
    """åˆ›å»ºè¿è¡Œæ‰€éœ€çš„æœ¬åœ°åŒ–å’Œ Schema æ–‡ä»¶"""
    if work_dir.exists():
        shutil.rmtree(work_dir)
    work_dir.mkdir(parents=True, exist_ok=True)

    # 1. Schema (fact_attributes.json)
    schema_content = {
        "zh": {
            "èŒä¸š": {
                "display_name": "èŒä¸š",
                "description": "è§’è‰²çš„å·¥ä½œæˆ–ç¤¾ä¼šèº«ä»½",
                "type": "ç¤¾ä¼šå±æ€§",
                "keywords": ["å·¥ä½œ", "èº«ä»½", "å¤´è¡”"]
            },
            "æ€§æ ¼": {
                "display_name": "æ€§æ ¼",
                "description": "è§’è‰²çš„å†…åœ¨æ€§æ ¼ç‰¹å¾ã€è„¾æ°”æˆ–è¡Œäº‹é£æ ¼",
                "type": "å†…åœ¨å±æ€§",
                "keywords": ["è„¾æ°”", "ä¸ªæ€§", "é£æ ¼"]
            },
            "æŠ€èƒ½": {
                "display_name": "æŠ€èƒ½",
                "description": "è§’è‰²æŒæ¡çš„ä¸“ä¸šæŠ€æœ¯æˆ–ç‰¹æ®Šèƒ½åŠ›",
                "type": "èƒ½åŠ›å±æ€§",
                "keywords": ["æ“…é•¿", "æŠ€æœ¯", "èƒ½åŠ›"]
            }
        }
    }
    schema_path = work_dir / "fact_attributes.json"
    with schema_path.open("w", encoding="utf-8") as f:
        json.dump(schema_content, f, ensure_ascii=False)

    # 2. Localization (zh.json)
    loc_content = {
        "zh": {
            "dossier": {
                "dossier_scene_header": "--- åœºæ™¯ ID: {scene_id} ---",
                "dossier_direct_header": "ç›´æ¥å‡ºåœº",
                "dossier_mentioned_header": "è¢«æåŠ",
                "dossier_dynamics_label": "ç”»é¢åŠ¨æ€:",
                "dossier_dialogue_header": "ç›¸å…³å¯¹è¯:",
                "dossier_dialogue_line": "  - {speaker}: {content}",
                "default_fact_type": "æœªåˆ†ç±»"
            },
            "attribute_labels": {"description": "æè¿°", "type": "ç±»å‹"}
        }
    }
    loc_path = work_dir / "zh.json"
    with loc_path.open("w", encoding="utf-8") as f:
        json.dump(loc_content, f, ensure_ascii=False)

    return schema_path, loc_path


# ==============================================================================
# 2. æ„é€  Mock è¾“å…¥æ•°æ® (NarrativeDataset)
# ==============================================================================
def create_mock_dataset(work_dir: Path) -> Path:
    """åˆ›å»ºä¸€ä¸ªåŸºäºã€Šç«æ˜Ÿæ•‘æ´ã€‹çš„ Mock Dataset æ–‡ä»¶"""

    # æ„é€ ä¸€ä¸ªå¼ºçƒˆçš„æµ‹è¯•ç”¨ä¾‹ï¼šåŒ…å«èŒä¸šè‡ªè¿°ã€æ€§æ ¼å±•ç°
    dataset_content = {
        "asset_uuid": str(uuid.uuid4()),
        "project_uuid": str(uuid.uuid4()),
        "project_metadata": {
            "asset_name": "The Martian (Mock Integration)",
            "project_name": "Real LLM Test",
            "version": "1.0",
            "issue_date": "2025-01-01",
            "annotator": "IntegrationScript",
            "description": "Testing CharacterIdentifier with Real Gemini"
        },
        "chapters": {
            "1": {"chapter_uuid": str(uuid.uuid4()), "local_id": 1, "name": "Sol 1", "scene_ids": ["101"]}
        },
        "scenes": {
            "101": {
                "scene_uuid": str(uuid.uuid4()),
                "id": 101,
                "start_time": "00:00:00.000",
                "end_time": "00:01:00.000",
                "scene_content_type": "Dialogue_Heavy",
                "inferred_location": "Ares 3 Hab",
                "character_dynamics": "Mark Watney records a video log, looking tired but determined.",
                "mood_and_atmosphere": "Desperate but Humorous",
                "dialogues": [
                    {
                        "speaker": "Mark Watney",
                        "content": "It's been 6 days since the rest of the crew thought I died. But guess what? I'm the best botanist on this planet.",
                        "start_time": "00:00:10.000",
                        "end_time": "00:00:15.000"
                    },
                    {
                        "speaker": "Mark Watney",
                        "content": "I'm going to have to science the shit out of this.",
                        "start_time": "00:00:20.000",
                        "end_time": "00:00:25.000"
                    }
                ],
                "captions": [],
                "highlights": []
            }
        },
        "narrative_storyline": {
            "root_branch_id": "main",
            "branches": {"main": {"branch_id": "main", "nodes": []}}
        }
    }

    script_path = work_dir / "enhanced_script.json"
    with script_path.open("w", encoding="utf-8") as f:
        json.dump(dataset_content, f, ensure_ascii=False)

    return script_path


# ==============================================================================
# 3. æ‰§è¡Œé›†æˆæµ‹è¯•
# ==============================================================================
def run_integration_test():
    # 1. Bootstrap: åŠ è½½ .env å’Œ é…ç½®
    print(">>> 1. Bootstrapping Environment...")
    settings, logger = bootstrap_local_env_and_logger(project_root)

    if not settings.GOOGLE_API_KEY:
        print("âŒ Error: GOOGLE_API_KEY not found in .env settings.")
        return

    work_dir = Path("./temp_real_integration_work")

    # 2. å‡†å¤‡èµ„æºå’Œæ•°æ®
    print(">>> 2. Preparing Resources & Data...")
    schema_path, loc_path = setup_temp_resources(work_dir)
    script_path = create_mock_dataset(work_dir)

    # 3. åˆå§‹åŒ–çœŸå®åŸºç¡€è®¾æ–½ (Real Infra)
    print(">>> 3. Initializing Real Infrastructure...")

    # [Real] Gemini Processor
    gemini_processor = GeminiProcessor(
        api_key=settings.GOOGLE_API_KEY,  # æ¥è‡ª .env
        logger=logger,
        debug_mode=settings.DEBUG,
        debug_dir=work_dir / "gemini_debug"
    )

    # [Real] Cost Calculator
    # æ³¨æ„ï¼šbootstrap.py ä¸­å·²ç»å°† .env çš„å®šä»·å‚æ•°è§£æä¸º settings.GEMINI_PRICING å­—å…¸
    cost_calculator = CostCalculator(
        pricing_data=settings.GEMINI_PRICING,
        usd_to_rmb_rate=settings.USD_TO_RMB_EXCHANGE_RATE
    )

    # 4. åˆå§‹åŒ–ä¸šåŠ¡æœåŠ¡ (Dependency Injection)
    identifier = CharacterIdentifier(
        gemini_processor=gemini_processor,  # æ³¨å…¥çœŸå® Processor
        cost_calculator=cost_calculator,  # æ³¨å…¥çœŸå® Calculator
        prompts_dir=work_dir,  # è¿™é‡Œæˆ‘ä»¬åœ¨ work_dir æ²¡æ”¾ prompt æ¨¡æ¿ï¼Œ
        # *æ³¨æ„*ï¼šå®é™…è¿è¡Œéœ€è¦ prompts_dir æŒ‡å‘çœŸå®çš„ prompts ç›®å½•ã€‚
        # å‡è®¾æ‚¨å·²å°† prompts å¤åˆ¶åˆ°äº† work_dir æˆ–è€…æŒ‡å‘é¡¹ç›®çœŸå®è·¯å¾„ã€‚
        # è¿™é‡Œæˆ‘ä»¬åšä¸€ä¸ªä¿®æ­£ï¼šæŒ‡å‘é¡¹ç›®çœŸå®è·¯å¾„ã€‚
        localization_path=loc_path,
        schema_path=schema_path,
        logger=logger,
        base_path=work_dir
    )

    # ä¿®æ­£ prompts_dir æŒ‡å‘çœŸå®é¡¹ç›®è·¯å¾„
    real_prompts_dir = project_root / "ai_services/biz_services/analysis/character/prompts"
    if real_prompts_dir.exists():
        identifier.prompts_dir = real_prompts_dir
        print(f"   Using real prompts from: {real_prompts_dir}")
    else:
        print(
            f"âš ï¸ Warning: Real prompts dir not found at {real_prompts_dir}. Test might fail if prompt template is missing.")

    # 5. æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    print("\n>>> ğŸš€ Executing Character Identification (Real API Call)...")
    try:
        result_envelope = identifier.execute(
            enhanced_script_path=script_path,
            characters_to_analyze=["Mark Watney"],
            lang="zh",
            model="gemini-2.5-flash",  # ä½¿ç”¨ .env ä¸­å®šä¹‰çš„ Flash æ¨¡å‹
            default_temp=0.1
        )

        # 6. å±•ç¤ºç»“æœ
        print("\n" + "=" * 30 + " REAL EXECUTION RESULT " + "=" * 30)

        data = result_envelope["data"]
        facts = data["result"]["identified_facts_by_character"].get("Mark Watney", [])
        usage = data["usage"]

        print(f"Status: {result_envelope['status']}")
        print(f"Facts Found: {len(facts)}")

        for fact in facts:
            # æ‰“å°è¯†åˆ«å‡ºçš„äº‹å®
            print(f"  - [{fact.get('type', 'æœªçŸ¥')}] {fact['attribute']}: {fact['value']}")
            print(f"    Quote: {fact.get('quote', '')}")
            print(f"    Confidence: {fact.get('confidence', 0)}")

        print("-" * 30)
        print("ğŸ’° Cost Report (Real Pricing):")
        print(f"  Model: {usage.get('model_name')}")
        print(f"  Input Tokens: {usage.get('prompt_tokens')}")
        print(f"  Output Tokens: {usage.get('completion_tokens')}")
        print(f"  Total Cost: ${usage.get('total_usd', 0):.6f} (Â¥{usage.get('total_rmb', 0):.4f})")
        print("=" * 60)

    except Exception as e:
        print(f"âŒ Execution Failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_integration_test()