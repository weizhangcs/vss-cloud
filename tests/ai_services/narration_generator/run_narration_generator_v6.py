import sys
import logging
import json
from pathlib import Path
from typing import Dict, Any, List
import uuid

# ==============================================================================
# 0. ç¯å¢ƒè·¯å¾„è®¾ç½® (Path Setup)
# ==============================================================================
# å½“å‰æ–‡ä»¶: tests/ai_services/narration_generator/run_narration_generator_v6.py
# ç›®æ ‡æ ¹ç›®å½•: é¡¹ç›®æ ¹ç›®å½• (å³ tests çš„ä¸Šä¸€çº§)
current_file = Path(__file__).resolve()
project_root = current_file.parents[3]  # å‘ä¸Š3çº§: narration_generator -> ai_services -> tests -> ROOT
sys.path.append(str(project_root))

print(f"Project Root added to path: {project_root}")

try:
    # å°è¯•å¯¼å…¥æ ¸å¿ƒç»„ä»¶ä»¥éªŒè¯è·¯å¾„
    from ai_services.biz_services.narrative_dataset import NarrativeDataset
    # [ä¿®æ­£] å¯¼å…¥ v5 æ–‡ä»¶å
    from ai_services.biz_services.narration.narration_generator_v5 import NarrationGenerator
    from ai_services.biz_services.narration.schemas import NarrationServiceConfig

    print("âœ… Successfully imported core modules.")
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    print("Please check your directory structure.")
    sys.exit(1)


# ==============================================================================
# 1. æ¨¡æ‹Ÿç»„ä»¶ (Mock Components)
# ==============================================================================

class MockGeminiProcessor:
    """æ¨¡æ‹Ÿ LLM å¤„ç†å™¨"""

    def generate_content(self, prompt: str, **kwargs) -> str:
        # ç®€å•æ¨¡æ‹Ÿè¿”å›ä¸€æ®µ JSON è„šæœ¬
        # æ³¨æ„ï¼šè¿™é‡Œæ¨¡æ‹Ÿäº†ä¸¤ä¸ªåœºæ™¯ï¼Œä¸€ä¸ªæ˜¯æ™®é€šçš„ï¼Œä¸€ä¸ªæ˜¯å€’å™çš„
        return """
        ```json
        {
            "narration_script": [
                {
                    "narration": "ç«æ˜ŸåŸºåœ°çš„åºŸå¢Ÿä¸­ï¼Œæ—¶é—´ä»¿ä½›å‡å›ºã€‚",
                    "narration_source": "Visual",
                    "source_scene_ids": [101],
                    "tts_instruct": "Slow and heavy."
                },
                {
                    "narration": "é‚£ä¸€åˆ»çš„è­¦æŠ¥å£°ï¼Œè‡³ä»Šä»åœ¨ä»–è„‘æµ·ä¸­å›è¡ã€‚",
                    "narration_source": "Visual",
                    "source_scene_ids": [102],
                    "tts_instruct": "Urgent and chaotic."
                }
            ]
        }
        ```
        """

    def count_tokens(self, text: str) -> int:
        return len(text) // 4


class MockCostCalculator:
    """æ¨¡æ‹Ÿè®¡è´¹å™¨"""

    def calculate(self, model, input_tok, output_tok):
        return {"total_usd": 0.001, "total_rmb": 0.007}


# ==============================================================================
# 2. æ„é€ æ•°æ® (Data Construction)
# ==============================================================================

def build_strict_dataset() -> Dict[str, Any]:
    """
    æ„é€ ç¬¦åˆ Strict Mode Schema çš„ Dataset å­—å…¸ã€‚
    """
    asset_uuid = str(uuid.uuid4())
    project_uuid = str(uuid.uuid4())

    # æ„é€  UUIDs
    ch1_uuid = str(uuid.uuid4())
    s101_uuid = str(uuid.uuid4())
    s102_uuid = str(uuid.uuid4())

    return {
        "asset_uuid": asset_uuid,
        "project_uuid": project_uuid,
        "project_metadata": {
            "asset_name": "The Martian Return",
            "project_name": "Test Project V6",
            "version": "1.0",
            "issue_date": "2025-12-16",
            "annotator": "Tester",
            "description": "Mock Data for V6 Logic Test"
        },
        "chapters": {
            "1": {
                "chapter_uuid": ch1_uuid,
                "local_id": 1,
                "name": "The Beginning",
                "scene_ids": ["101", "102"]
            }
        },
        "scenes": {
            "101": {
                "scene_uuid": s101_uuid,
                "id": 101,
                "start_time": "00:00:00.000",
                "end_time": "00:00:10.000",  # Duration 10s
                "scene_content_type": "Establishing_Shot",
                "inferred_location": "Mars Base",
                "character_dynamics": "Wide shot of the desolate base.",
                "mood_and_atmosphere": "Quiet, Dead",
                "dialogues": [],
                "captions": [{"content": "3 Years Later", "type": "Time", "start_time": "00:00:01.000",
                              "end_time": "00:00:03.000"}],
                "highlights": []
            },
            "102": {
                "scene_uuid": s102_uuid,
                "id": 102,
                "start_time": "00:00:10.000",
                "end_time": "00:00:15.500",  # Duration 5.5s
                "scene_content_type": "Internal_Monologue",
                "inferred_location": "Cockpit",
                "character_dynamics": "Flashback of the crash. Red lights flashing.",
                "mood_and_atmosphere": "Panic",
                "dialogues": [{"speaker": "AI", "content": "Critical Alert! Eject!", "start_time": "00:00:10.500",
                               "end_time": "00:00:12.000"}],
                "captions": [],
                "highlights": [{"description": "Explosion", "type": "Action", "start_time": "00:00:14.000",
                                "end_time": "00:00:15.000", "tags": ["Fire"]}]
            }
        },
        "narrative_storyline": {
            "root_branch_id": "main",
            "branches": {
                "main": {
                    "branch_id": "main",
                    "nodes": [
                        {
                            "local_id": 101,
                            "narrative_index": 1,
                            "narrative_function": "LINEAR",
                            "ref_scene_id": None
                        },
                        {
                            "local_id": 102,
                            "narrative_index": 2,
                            # [æ ¸å¿ƒæµ‹è¯•ç‚¹] éªŒè¯ ContextEnhancer æ˜¯å¦èƒ½è¯†åˆ«è¿™ä¸ªå€’å™
                            "narrative_function": "FLASHBACK",
                            "ref_scene_id": 101,
                            "display_label": "The Crash Memory"
                        }
                    ]
                }
            }
        }
    }


# ==============================================================================
# 3. æ‰§è¡Œæµ‹è¯• (Execution)
# ==============================================================================

def run_test():
    # Setup Logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    logger = logging.getLogger("TestV6")

    # 1. è‡ªåŠ¨å®šä½èµ„æºç›®å½• (é¿å… FileNotFoundError)
    # èµ„æºä½äº: ai_services/biz_services/narration/prompts
    narration_root = project_root / "ai_services/biz_services/narration"
    prompts_dir = narration_root / "prompts"
    metadata_dir = narration_root / "metadata"

    # éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨
    if not prompts_dir.exists():
        logger.warning(f"âš ï¸ Prompts dir not found at {prompts_dir}, using mock path.")
    if not metadata_dir.exists():
        logger.warning(f"âš ï¸ Metadata dir not found at {metadata_dir}, using mock path.")

    # 2. åˆå§‹åŒ– Generator
    generator = NarrationGenerator(
        project_id="mock-project",
        location="us-central1",
        prompts_dir=prompts_dir,
        metadata_dir=metadata_dir,
        rag_schema_path=Path("./schema"),  # Mock path
        logger=logger,
        work_dir=Path("./work"),
        gemini_processor=MockGeminiProcessor(),
        cost_calculator=MockCostCalculator()
    )

    # 3. å‡†å¤‡ Mock è¾“å…¥
    mock_chunks = [
        {"source_uri": "gs://bucket/assets/v6_test/_scene_101_enhanced.txt", "content": "dummy content"},
        {"source_uri": "gs://bucket/assets/v6_test/_scene_102_enhanced.txt", "content": "dummy content"}
    ]

    # 4. å‡†å¤‡ Config (Payload)
    dataset_dict = build_strict_dataset()

    config_payload = {
        "asset_name": "The Martian Return",
        "lang": "zh",
        "model": "gemini-pro",
        "control_params": {
            "style": "Cinematic",
            "perspective": "third_person",
            "target_duration_minutes": 1.0,
            "speaking_rate": 4.5,
            "narrative_focus": "custom",
            "custom_prompts": {"narrative_focus": "Focus on the isolation."}
        },
        # [Strict] å¿…é¡»åŒ…å« narrative_dataset
        "narrative_dataset": dataset_dict
    }

    print("\n>>> ğŸš€ Starting Narration Generator V6 Test (Mock Mode)...\n")

    try:
        # --- Step 1: Config Validation (Dataset Initialization) ---
        logger.info("[Step 1] Validating Config & Initializing Dataset...")
        # è¿™ä¸€æ­¥ä¼šè§¦å‘ NarrativeDataset çš„ Pydantic æ ¡éªŒï¼Œå¹¶è‡ªåŠ¨è®¡ç®— duration
        service_config = generator._validate_config(config_payload)

        # éªŒè¯è®¡ç®—å­—æ®µ
        scene_101 = service_config.narrative_dataset.scenes["101"]
        scene_102 = service_config.narrative_dataset.scenes["102"]

        logger.info(f"âœ… Dataset Validated.")
        logger.info(f"   Scene 101 Duration: {scene_101.duration}s (Expected 10.0)")
        logger.info(f"   Scene 102 Duration: {scene_102.duration}s (Expected 5.5)")

        assert scene_101.duration == 10.0
        assert scene_102.duration == 5.5

        # --- Step 2: Context Enhancer ---
        logger.info("[Step 2] Enhancing Context (Reconstruction)...")
        # è¿™ä¸€æ­¥ä¼šè°ƒç”¨ ContextEnhancerï¼Œæµ‹è¯•å…¶æ˜¯å¦èƒ½è¯»å– Storyline é€»è¾‘
        context = generator._prepare_context(mock_chunks, service_config)

        print("\n" + "=" * 20 + " GENERATED CONTEXT SNAPSHOT " + "=" * 20)
        print(context)
        print("=" * 60 + "\n")

        # éªŒè¯ Context å†…å®¹
        if "FLASHBACK" in context and "relative to Scene 101" in context:
            logger.info("âœ… SUCCESS: FLASHBACK logic correctly injected into context.")
        else:
            logger.error("âŒ FAILURE: FLASHBACK logic missing from context.")

        if "Text: 3 Years Later" in context:
            logger.info("âœ… SUCCESS: Caption '3 Years Later' correctly injected.")

        # --- Step 3: Prompt Construction ---
        logger.info("[Step 3] Constructing Prompt...")
        prompt = generator._construct_prompt(context, service_config)
        logger.info(f"âœ… Prompt assembled (Length: {len(prompt)} chars).")

        # --- Step 4: Generation (Mock LLM) ---
        logger.info("[Step 4] Mocking LLM Generation...")
        # æ¨¡æ‹Ÿçˆ¶ç±» BaseRagGenerator.generate çš„éƒ¨åˆ†é€»è¾‘
        llm_response_str = generator.gemini_processor.generate_content(prompt)
        llm_response_json = json.loads(llm_response_str.replace("```json", "").replace("```", ""))

        # --- Step 5: Post Process (Validator) ---
        logger.info("[Step 5] Post-Processing (Validator)...")
        # è¿™ä¸€æ­¥æµ‹è¯• Generator æ˜¯å¦æ­£ç¡®åœ°å°† Dataset Dump ä¼ ç»™äº† Validator
        # ä¸” Validator èƒ½å¦æ­£ç¡®æ ¡éªŒæ— å¸§çš„ duration
        final_result = generator._post_process(
            llm_response_json,
            service_config,
            {"total_tokens": 100},
            rag_context=context
        )

        script = final_result['narration_script']
        logger.info(f"âœ… Pipeline Complete. Generated {len(script)} snippets.")

        # æ£€æŸ¥ Validator ç»“æœ
        s1 = script[0]  # Scene 101, Duration 10s. Text: "ç«æ˜ŸåŸºåœ°çš„åºŸå¢Ÿä¸­ï¼Œæ—¶é—´ä»¿ä½›å‡å›ºã€‚" (15å­—)

        # å®‰å…¨è·å– metadata (é˜²æ­¢ä¸º None)
        meta1 = s1.get('metadata', {})
        validation_msg = meta1.get('validation_error') or 'Passed'
        pred_dur = meta1.get('pred_audio_duration', 'N/A')
        limit = meta1.get('duration_limit', 'N/A')

        logger.info(f"   Snippet 101 Validation: {validation_msg}")
        logger.info(f"   Snippet 101 Duration: Pred={pred_dur}s / Limit={limit}s")

        s2 = script[1]
        meta2 = s2.get('metadata', {})
        validation_msg2 = meta2.get('validation_error') or 'Passed'
        logger.info(f"   Snippet 102 Validation: {validation_msg2}")

    except Exception as e:
        logger.error(f"âŒ Test Failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_test()