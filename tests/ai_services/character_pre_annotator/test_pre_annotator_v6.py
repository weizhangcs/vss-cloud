# tests/ai_services/character_pre_annotator/test_pre_annotator_v6.py

import sys
import json
import logging
from pathlib import Path

# ==============================================================================
# 0. ç¯å¢ƒè·¯å¾„è®¾ç½®
# ==============================================================================
# å®šä½åˆ°é¡¹ç›®æ ¹ç›®å½• (tests/../..)
current_file = Path(__file__).resolve()
project_root = current_file.parents[3]
sys.path.append(str(project_root))

from ai_services.ai_platform.llm.gemini_processor import GeminiProcessor
from ai_services.ai_platform.llm.cost_calculator import CostCalculator
from ai_services.biz_services.character_pre_annotator.service import CharacterPreAnnotatorService
from tests.lib.bootstrap import bootstrap_local_env_and_logger


def create_mock_srt(work_dir: Path) -> Path:

    srt_path = work_dir / "mock_dialogue.srt"
    return srt_path


def run_test():
    # 1. å¼•å¯¼ç¯å¢ƒ
    settings, logger = bootstrap_local_env_and_logger(project_root)

    if not settings.GOOGLE_API_KEY:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° GOOGLE_API_KEY")
        return

    # å‡†å¤‡å·¥ä½œç›®å½•
    work_dir = project_root / "shared_media" / "tmp" / "pre_annotator_test"
    work_dir.mkdir(parents=True, exist_ok=True)

    # 2. å‡†å¤‡æ•°æ®
    srt_path = create_mock_srt(work_dir)
    print(f">>> [Step 1] Mock SRT created at: {srt_path}")

    # 3. åˆå§‹åŒ–åŸºç¡€è®¾æ–½
    print(">>> [Step 2] Init Infra (Processor V2)...")
    processor = GeminiProcessor(
        api_key=settings.GOOGLE_API_KEY,
        logger=logger,
        debug_mode=True,
        debug_dir=work_dir / "debug_logs"
    )

    calculator = CostCalculator(
        pricing_data=settings.GEMINI_PRICING,
        usd_to_rmb_rate=settings.USD_TO_RMB_EXCHANGE_RATE
    )

    # 4. åˆå§‹åŒ–ä¸šåŠ¡æœåŠ¡
    print(">>> [Step 3] Init Service (CharacterPreAnnotator)...")
    service = CharacterPreAnnotatorService(
        logger=logger,
        gemini_processor=processor,
        cost_calculator=calculator
    )

    # 5. æ„é€  Payload
    # æ³¨æ„ï¼šæˆ‘ä»¬æ•…æ„åªç»™éƒ¨åˆ†å·²çŸ¥è§’è‰²ï¼Œæµ‹è¯• AI çš„æ¨ç†èƒ½åŠ›
    # åŒæ—¶æµ‹è¯• "è½¦æ˜Ÿæ˜Ÿ" -> "è½¦å°å°" çš„å½’ä¸€åŒ–èƒ½åŠ›
    payload = {
        "subtitle_path": str(srt_path),
        "known_characters": ["æ¥šæ˜Šè½©", "è½¦å°å°","å®‹å®‰å¨œ"],
        "video_title": "æ€»è£çš„å¥‘çº¦å¥³å‹",
        "lang": "zh",
        "model_name": "gemini-2.5-flash"
    }

    # 6. æ‰§è¡Œ
    print(">>> [Step 4] Executing Pipeline...")
    try:
        result = service.execute(payload)

        print("\n" + "=" * 40)
        print("âœ… æµ‹è¯•æˆåŠŸ! ç»“æœæ‘˜è¦:")
        print("=" * 40)

        # 1. æ‰“å°è§’è‰²åˆ†æ
        roster = result.get("character_roster", [])
        print(f"\nğŸ‘¥ è§’è‰²æ´»è·ƒåº¦åˆ†æ ({len(roster)}äºº):")
        for char in roster:
            # å…¼å®¹ Pydantic å¯¹è±¡æˆ– Dict
            c_dict = char.model_dump() if hasattr(char, 'model_dump') else char
            print(f"   - {c_dict['name']} (Variations: {c_dict['variations']})")
            print(f"     Lines: {c_dict['stats']['lines']}, Weight: {c_dict['weight_percent']}")

        # 2. æ‰“å°å­—å¹•æµ (æŠ½æ ·)
        subs = result.get("optimized_subtitles", [])
        print(f"\nğŸ“œ å­—å¹•æµæŠ½æ · (å‰5å¥):")
        for item in subs[:5]:
            i_dict = item.model_dump() if hasattr(item, 'model_dump') else item
            print(f"   [{i_dict['index']}] {i_dict['speaker']}: {i_dict['content']}")

        # 3. æ‰“å°æˆæœ¬
        usage = result.get("usage_report", {})
        print(f"\nğŸ’° æˆæœ¬æŠ¥å‘Š:")
        print(f"   Total Tokens: {usage.get('total_tokens')}")
        print(f"   Cost: ${usage.get('cost_usd', 0):.6f} (Â¥{usage.get('cost_rmb', 0):.4f})")

        # 4. éªŒè¯ ASS ç”Ÿæˆ
        ass_path = result.get("output_ass_path")
        if ass_path:
            print(f"\nğŸ“ ASS æ–‡ä»¶ç”Ÿæˆ: {ass_path}")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_test()